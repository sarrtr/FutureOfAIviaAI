{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-18T10:20:15.621599Z",
     "iopub.status.busy": "2025-12-18T10:20:15.621327Z",
     "iopub.status.idle": "2025-12-18T10:20:27.004999Z",
     "shell.execute_reply": "2025-12-18T10:20:27.004320Z",
     "shell.execute_reply.started": "2025-12-18T10:20:15.621574Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.21.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision) (1.26.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: torch-geometric in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.7.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-geometric) (3.13.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-geometric) (2025.3.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-geometric) (3.1.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-geometric) (1.26.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-geometric) (3.2.1)\n",
      "Requirement already satisfied: requests in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-geometric) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->torch-geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->torch-geometric) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->torch-geometric) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->torch-geometric) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->torch-geometric) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->torch-geometric) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->torch-geometric) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->torch-geometric) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch-geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torch-geometric) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torch-geometric) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torch-geometric) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Requirement already satisfied: networkx in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.4.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.26.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.67.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kuzzm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n",
    "!pip install torch-geometric\n",
    "!pip install networkx scikit-learn numpy pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T10:20:27.006850Z",
     "iopub.status.busy": "2025-12-18T10:20:27.006617Z",
     "iopub.status.idle": "2025-12-18T10:20:37.630155Z",
     "shell.execute_reply": "2025-12-18T10:20:37.629403Z",
     "shell.execute_reply.started": "2025-12-18T10:20:27.006825Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kuzzm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\__init__.py:4: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: [WinError 127] Не найдена указанная процедура\n",
      "  import torch_geometric.typing\n",
      "C:\\Users\\kuzzm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\__init__.py:4: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: [WinError 127] Не найдена указанная процедура\n",
      "  import torch_geometric.typing\n",
      "C:\\Users\\kuzzm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\__init__.py:4: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: [WinError 127] Не найдена указанная процедура\n",
      "  import torch_geometric.typing\n",
      "C:\\Users\\kuzzm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\__init__.py:4: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: [WinError 127] Не найдена указанная процедура\n",
      "  import torch_geometric.typing\n",
      "C:\\Users\\kuzzm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_source=\"SemanticGraph_delta_1_cutoff_0_minedge_1.pkl\"\n",
    "save_predictions_path = \"predictions.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Help functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T10:20:37.631623Z",
     "iopub.status.busy": "2025-12-18T10:20:37.631098Z",
     "iopub.status.idle": "2025-12-18T10:20:37.643122Z",
     "shell.execute_reply": "2025-12-18T10:20:37.642625Z",
     "shell.execute_reply.started": "2025-12-18T10:20:37.631582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def structural_features(G: nx.Graph, u: int, v: int, max_shortest=6):\n",
    "    \"\"\"\n",
    "    Computes set of structural graph features for a node pair (u, v):\n",
    "        1. Common Neighbors: Number of nodes connected to both u and v\n",
    "        2. Jaccard Coefficient: Normalized measure of neighborhood overlap\n",
    "        3. Adamic-Adar Index: Weighted version of common neighbors (favors rare neighbors)\n",
    "        4. Node Degrees: Connectivity information for both nodes\n",
    "        5. Shortest Path Length: Distance between nodes (capped for efficiency)\n",
    "    \"\"\"\n",
    "    # Common Neighbors\n",
    "    try:\n",
    "        cn = len(list(nx.common_neighbors(G, u, v)))\n",
    "    except Exception:\n",
    "        cn = 0\n",
    "    \n",
    "    # Jaccard Coefficient\n",
    "    j = 0.0\n",
    "    try:\n",
    "        jc = next(nx.jaccard_coefficient(G, [(u,v)]))[2]\n",
    "        j = jc if jc is not None else 0.0\n",
    "    except Exception:\n",
    "        j = 0.0\n",
    "    \n",
    "    # Adamic-Adar Index\n",
    "    aa = 0.0\n",
    "    try:\n",
    "        aa = next(nx.adamic_adar_index(G, [(u,v)]))[2] or 0.0\n",
    "    except Exception:\n",
    "        aa = 0.0\n",
    "    \n",
    "    # Node Degrees: Number of edges incident to each node\n",
    "    # Provides information about node importance/centrality in the network\n",
    "    du = G.degree(u)\n",
    "    dv = G.degree(v)\n",
    "    \n",
    "    # Shortest Path Length: Minimum number of edges to traverse from u to v\n",
    "    # Capped at max_shortest to avoid expensive computations for disconnected nodes\n",
    "    try:\n",
    "        spl = nx.shortest_path_length(G, source=u, target=v)\n",
    "        if spl > max_shortest:\n",
    "            spl = max_shortest\n",
    "    except Exception:\n",
    "        # Nodes are disconnected (no path exists)\n",
    "        spl = max_shortest\n",
    "    \n",
    "    return [cn, j, aa, du, dv, spl]\n",
    "\n",
    "def build_pair_features(pairs: List[Tuple[int,int]], emb: np.ndarray, G: nx.Graph):\n",
    "    \"\"\"\n",
    "    Constructs a comprehensive feature matrix for node pairs by combining learned embeddings\n",
    "    with structural graph features.\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "    for (u, v) in pairs:\n",
    "        # Extract learned embeddings for both nodes\n",
    "        zu = emb[u]\n",
    "        zv = emb[v]\n",
    "        \n",
    "        # Vector-based features from embeddings:\n",
    "        # - Concatenation of both embeddings (preserves individual node information)\n",
    "        # - Element-wise product (captures interaction patterns)\n",
    "        # - Absolute difference (captures similarity/dissimilarity)\n",
    "        vec = np.concatenate([zu, zv, zu * zv, np.abs(zu - zv)], axis=0)\n",
    "        \n",
    "        # Structural features from graph topology\n",
    "        sf = structural_features(G, u, v)\n",
    "        \n",
    "        # Combine embedding-based and structural features into single feature vector\n",
    "        feat = np.concatenate([vec, np.array(sf, dtype=float)], axis=0)\n",
    "        feats.append(feat)\n",
    "    \n",
    "    return np.vstack(feats)\n",
    "\n",
    "def sample_negatives(G: nx.Graph, num_samples: int, forbid_set:set):\n",
    "    \"\"\"\n",
    "    Samples random negative (non-edge) pairs from the graph for training.\n",
    "    \"\"\"\n",
    "    negs = set()\n",
    "    n = G.number_of_nodes()\n",
    "    \n",
    "    while len(negs) < num_samples:\n",
    "        u = random.randrange(n)\n",
    "        v = random.randrange(n)\n",
    "        \n",
    "        # Skip self-loops\n",
    "        if u == v:\n",
    "            continue\n",
    "        \n",
    "        # Normalize pair ordering (u < v) for consistent representation\n",
    "        key = (min(u, v), max(u, v))\n",
    "        \n",
    "        # Skip if this pair is forbidden (exists in training or future edges)\n",
    "        if key in forbid_set:\n",
    "            continue\n",
    "        \n",
    "        negs.add(key)\n",
    "    \n",
    "    return list(negs)\n",
    "\n",
    "def precision_at_k(y_true: np.ndarray, y_score: np.ndarray, K=100):\n",
    "    \"\"\"\n",
    "    Computes Precision@K metric for link prediction evaluation.\n",
    "    \"\"\"\n",
    "    idx = np.argsort(-y_score)[:K]\n",
    "    return y_true[idx].sum() / float(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GraphSAGE encoder and pair-MLP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T10:20:37.644356Z",
     "iopub.status.busy": "2025-12-18T10:20:37.644013Z",
     "iopub.status.idle": "2025-12-18T10:20:37.665487Z",
     "shell.execute_reply": "2025-12-18T10:20:37.664951Z",
     "shell.execute_reply.started": "2025-12-18T10:20:37.644314Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GraphSAGEEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    GraphSAGE encoder for learning node embeddings.\n",
    "    \n",
    "    The encoder uses GraphSAGE convolutional layers which:\n",
    "    - Sample a fixed-size neighborhood for each node\n",
    "    - Aggregate neighbor features\n",
    "    - Combine aggregated neighbor features with the node's own features\n",
    "    - Apply non-linear activation (ReLU) to learn complex patterns\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, hidden_channels=128, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "class PairMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Layer Perceptron (MLP) classifier for link prediction on node pairs.\n",
    "    \n",
    "    Architecture:\n",
    "        Input -> FC1 (hidden1) -> ReLU -> FC2 (hidden2) -> ReLU -> Output (1) -> Sigmoid\n",
    "    \n",
    "    Attributes:\n",
    "        fc1 (nn.Linear): First fully connected layer mapping input to first hidden dimension\n",
    "        fc2 (nn.Linear): Second fully connected layer mapping first to second hidden dimension\n",
    "        out (nn.Linear): Output layer mapping second hidden dimension to single logit\n",
    "    \n",
    "    Args:\n",
    "        in_dim (int): Dimensionality of input feature vectors (4*embedding_dim + 6)\n",
    "        hidden1 (int, optional): Size of first hidden layer. Defaults to 256.\n",
    "        hidden2 (int, optional): Size of second hidden layer. Defaults to 64.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, hidden1=256, hidden2=64):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.out = nn.Linear(hidden2, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.sigmoid(self.out(x)).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T10:20:37.667354Z",
     "iopub.status.busy": "2025-12-18T10:20:37.666838Z",
     "iopub.status.idle": "2025-12-18T10:20:39.544581Z",
     "shell.execute_reply": "2025-12-18T10:20:39.543989Z",
     "shell.execute_reply.started": "2025-12-18T10:20:37.667327Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(data_source, \"rb\" ) as pkl_file:\n",
    "    full_dynamic_graph_sparse, unconnected_vertex_pairs, unconnected_vertex_pairs_solution, year_start, years_delta, vertex_degree_cutoff, min_edges = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create graph and node features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T10:20:39.545820Z",
     "iopub.status.busy": "2025-12-18T10:20:39.545504Z",
     "iopub.status.idle": "2025-12-18T10:21:08.988021Z",
     "shell.execute_reply": "2025-12-18T10:21:08.987447Z",
     "shell.execute_reply.started": "2025-12-18T10:20:39.545781Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "G_train = nx.Graph()\n",
    "\n",
    "# infer maximum node id from the edges\n",
    "max_id = int(max(full_dynamic_graph_sparse[:, 0].max(),\n",
    "                 full_dynamic_graph_sparse[:, 1].max()))\n",
    "\n",
    "G_train.add_nodes_from(range(max_id + 1))\n",
    "G_train.add_edges_from(zip(full_dynamic_graph_sparse[:, 0],\n",
    "                           full_dynamic_graph_sparse[:, 1]))\n",
    "\n",
    "n_nodes = max_id + 1\n",
    "\n",
    "deg = np.array([G_train.degree(i) for i in range(n_nodes)], dtype=float).reshape(-1, 1)\n",
    "\n",
    "# Normalize degrees\n",
    "deg = deg / (deg.max() + 1e-9)\n",
    "\n",
    "# Random node features\n",
    "rand_feat = np.random.randn(n_nodes, 16).astype(np.float32)\n",
    "\n",
    "# Final node feature matrix \n",
    "node_features = np.concatenate([deg.astype(np.float32), rand_feat], axis=1)  # shape (n_nodes, 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train GraphSAGE encoder to learn node embeddings from graph structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T10:21:08.989249Z",
     "iopub.status.busy": "2025-12-18T10:21:08.988869Z",
     "iopub.status.idle": "2025-12-18T10:26:52.139371Z",
     "shell.execute_reply": "2025-12-18T10:26:52.138328Z",
     "shell.execute_reply.started": "2025-12-18T10:21:08.989221Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:115] data. DefaultCPUAllocator: not enough memory: you tried to allocate 11908202496 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m optimizer.zero_grad()\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# compute node embeddings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m emb = \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyg_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpyg_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# extract source and destination nodes for all edges\u001b[39;00m\n\u001b[32m     21\u001b[39m src = edge_index[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mGraphSAGEEncoder.forward\u001b[39m\u001b[34m(self, x, edge_index)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index):\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.convs:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m         x = \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m         x = F.relu(x)\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\nn\\conv\\sage_conv.py:134\u001b[39m, in \u001b[36mSAGEConv.forward\u001b[39m\u001b[34m(self, x, edge_index, size)\u001b[39m\n\u001b[32m    131\u001b[39m     x = (\u001b[38;5;28mself\u001b[39m.lin(x[\u001b[32m0\u001b[39m]).relu(), x[\u001b[32m1\u001b[39m])\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m out = \u001b[38;5;28mself\u001b[39m.lin_l(out)\n\u001b[32m    137\u001b[39m x_r = x[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Temp\\torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_5dbnyyf4.py:173\u001b[39m, in \u001b[36mpropagate\u001b[39m\u001b[34m(self, edge_index, x, size)\u001b[39m\n\u001b[32m    167\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.update(\n\u001b[32m    168\u001b[39m         out,\n\u001b[32m    169\u001b[39m     )\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmutable_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m     \u001b[38;5;66;03m# Begin Message Forward Pre Hook #######################################\u001b[39;00m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Temp\\torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_5dbnyyf4.py:83\u001b[39m, in \u001b[36mcollect\u001b[39m\u001b[34m(self, edge_index, x, size)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_x_0, Tensor):\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_size(size, \u001b[32m0\u001b[39m, _x_0)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     x_j = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_index_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_x_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_j\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     85\u001b[39m     x_j = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:267\u001b[39m, in \u001b[36mMessagePassing._index_select\u001b[39m\u001b[34m(self, src, index)\u001b[39m\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m src.index_select(\u001b[38;5;28mself\u001b[39m.node_dim, index)\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_index_select_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:290\u001b[39m, in \u001b[36mMessagePassing._index_select_safe\u001b[39m\u001b[34m(self, src, index)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (index.numel() > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index.max() >= src.size(\u001b[38;5;28mself\u001b[39m.node_dim)):\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[32m    283\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound indices in \u001b[39m\u001b[33m'\u001b[39m\u001b[33medge_index\u001b[39m\u001b[33m'\u001b[39m\u001b[33m that are larger \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    284\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mthan \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc.size(\u001b[38;5;28mself\u001b[39m.node_dim)\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (got \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    287\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33min the interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc.size(\u001b[38;5;28mself\u001b[39m.node_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) in \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    288\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33myour node feature matrix and try again.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:271\u001b[39m, in \u001b[36mMessagePassing._index_select_safe\u001b[39m\u001b[34m(self, src, index)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_index_select_safe\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: Tensor, index: Tensor) -> Tensor:\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    273\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m index.numel() > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index.min() < \u001b[32m0\u001b[39m:\n",
      "\u001b[31mRuntimeError\u001b[39m: [enforce fail at alloc_cpu.cpp:115] data. DefaultCPUAllocator: not enough memory: you tried to allocate 11908202496 bytes."
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "pyg_data = from_networkx(G_train)\n",
    "pyg_data.x = torch.tensor(node_features, dtype=torch.float32)\n",
    "pyg_data = pyg_data.to(device)\n",
    "\n",
    "encoder = GraphSAGEEncoder(in_channels=pyg_data.x.size(1), hidden_channels=128, num_layers=2).to(device)\n",
    "optimizer = torch.optim.Adam(encoder.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "encoder.train()\n",
    "\n",
    "edge_index = pyg_data.edge_index\n",
    "\n",
    "# learn embeddings using link prediction as self-supervised task\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # compute node embeddings\n",
    "    emb = encoder(pyg_data.x, pyg_data.edge_index)\n",
    "    \n",
    "    # extract source and destination nodes for all edges\n",
    "    src = edge_index[0]\n",
    "    dst = edge_index[1]\n",
    "    \n",
    "    # similarity scores for positive pairs using dot product\n",
    "    pos_scores = (emb[src] * emb[dst]).sum(dim=1)\n",
    "    \n",
    "    # Positive loss\n",
    "    pos_loss = -F.logsigmoid(pos_scores).mean()\n",
    "    \n",
    "    # randomly sampled non-edges\n",
    "    n_pos = src.size(0)\n",
    "    \n",
    "    # Sample random negative pairs: keep source nodes, randomize destinations\n",
    "    neg_u = src[torch.randint(0, n_pos, (n_pos,)).to(device)]\n",
    "    neg_v = torch.randint(0, emb.size(0), (n_pos,)).to(device)\n",
    "    \n",
    "    # Compute similarity scores for negative pairs\n",
    "    neg_scores = (emb[neg_u] * emb[neg_v]).sum(dim=1)\n",
    "    \n",
    "    # Negative loss\n",
    "    neg_loss = -F.logsigmoid(-neg_scores).mean()\n",
    "    \n",
    "    # Total loss\n",
    "    loss = pos_loss + neg_loss\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch} loss {loss.item():.4f}\")\n",
    "\n",
    "# final node embeddings\n",
    "encoder.eval()\n",
    "with torch.no_grad():\n",
    "    node_emb = encoder(pyg_data.x, pyg_data.edge_index).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare X and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-18T10:26:52.140094Z",
     "iopub.status.idle": "2025-12-18T10:26:52.140459Z",
     "shell.execute_reply": "2025-12-18T10:26:52.140340Z",
     "shell.execute_reply.started": "2025-12-18T10:26:52.140318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# candidate pairs and labels from dataset\n",
    "pairs_all = [tuple(p) for p in unconnected_vertex_pairs]\n",
    "pairs_all = [(min(u, v), max(u, v)) for (u, v) in pairs_all]\n",
    "\n",
    "# Labels: 1 if the pair gains >= min_edges edges between year_start and year_start+years_delta\n",
    "y = np.array(unconnected_vertex_pairs_solution, dtype=int)\n",
    "\n",
    "print(\"Pairs total:\", len(pairs_all), \"positives:\", int(y.sum()), \"negatives:\", int((1 - y).sum()))\n",
    "\n",
    "# Build feature matrix for all candidate pairs using G_train and learned embeddings\n",
    "X = build_pair_features(pairs_all, node_emb, G_train)\n",
    "print(\"Feature matrix shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train MLP classifier to predict link existence from pair features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-18T10:26:52.141508Z",
     "iopub.status.idle": "2025-12-18T10:26:52.141826Z",
     "shell.execute_reply": "2025-12-18T10:26:52.141692Z",
     "shell.execute_reply.started": "2025-12-18T10:26:52.141673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_val_t = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val_t = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "\n",
    "model = PairMLP(X_train.shape[1]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "batch_size = 128\n",
    "num_epochs = 40\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle training data each epoch for better generalization\n",
    "    perm = torch.randperm(X_train_t.size(0))\n",
    "    losses = []\n",
    "    model.train()\n",
    "    \n",
    "    for i in range(0, X_train_t.size(0), batch_size):\n",
    "        idx = perm[i:i+batch_size]\n",
    "        xb = X_train_t[idx]\n",
    "        yb = y_train_t[idx]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(xb)\n",
    "     \n",
    "        loss = F.binary_cross_entropy(out, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    # evaluation on validation set \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_val_t).cpu().numpy()\n",
    "        auc = roc_auc_score(y_val, preds)\n",
    "        ap = average_precision_score(y_val, preds)\n",
    "    model.train()\n",
    "    print(f\"Epoch {epoch} train_loss={np.mean(losses):.4f} val_auc={auc:.4f} val_ap={ap:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final evaluation on the complete dataset (training + validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-18T10:26:52.142835Z",
     "iopub.status.idle": "2025-12-18T10:26:52.143080Z",
     "shell.execute_reply": "2025-12-18T10:26:52.142984Z",
     "shell.execute_reply.started": "2025-12-18T10:26:52.142968Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds_all = model(torch.tensor(X_scaled, dtype=torch.float32).to(device)).cpu().numpy()\n",
    "\n",
    "auc_all = roc_auc_score(y, preds_all)\n",
    "ap_all = average_precision_score(y, preds_all)\n",
    "prec100 = precision_at_k(y, preds_all, K=min(100, len(y)))\n",
    "print(\"Final metrics: AUC\", auc_all, \"AP\", ap_all, \"Precision@100\", prec100)\n",
    "\n",
    "# Save predictions to CSV file\n",
    "out_df = pd.DataFrame({\n",
    "    \"u\": [p[0] for p in pairs_all],\n",
    "    \"v\": [p[1] for p in pairs_all],\n",
    "    \"label\": list(y.astype(int)), # 1=edge, 0=non-edge\n",
    "    \"score\": list(preds_all)\n",
    "})\n",
    "os.makedirs(os.path.dirname(save_predictions_path), exist_ok=True)\n",
    "out_df.to_csv(save_predictions_path, index=False)\n",
    "print(\"Saved predictions to\", save_predictions_path)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9063230,
     "sourceId": 14209230,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
